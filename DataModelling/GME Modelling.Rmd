---
title: "GME - modelling"
author: "Julius Antonio Bladt"
date: "07/04/2021"
output: html_document
---

```{R}
library(caret)

# Load data
gme <- read.delim("C:/Users/Julius Antonio Bladt/Desktop/PredictStockusingRedditandTwitter-main/PreProcessedData/GME_merged.csv", sep="," )

gme <- gme[-48,] # remove last hour lead movement observation
train <- gme[1:35, -c(1:7)]
test <- gme[36:47, -c(1:7)]

```


Logistic regression fit:

```{R}

gme.logit <- glm(lead_movement ~ ., family="binomial", data=train)
pred <- predict(gme.logit, newdata=test, type="response")


summary(gme.logit)
confusionMatrix(factor(ifelse(pred > 0.5, "1", "0")), 
                factor(test$lead_movement), positive = "1") 

```
None of our variables are significant in explaining the effect on lead movement. This is obviously not optimal, as it speaks against our ability to use stock sentiments to explain the movement of price in the Gamestop Stock. Next I will try to use a random forrest to predict:


```{R}
gme_all <- gme[ , -c(1:7)]
gme_all$lead_movement <- as.factor(gme_all$lead_movement)

library(tree)
# set a classsification tree
tree.gme = tree(lead_movement ~ ., data=gme_all, split = c("deviance", "gini"))
summary(tree.gme)

# plot tree
plot(tree.gme)
text(tree.gme,pretty=0)

```
As can be seen from the plot, the most important variable in predicting the lead movement of GME stock is superfluous. If the share of superfluous sentiment is low, the next most important is litigious. And if the superfluous is high, the second most important is uncertainty.

Now to estimate the test error:

```{R}
train$lead_movement <- as.factor(train$lead_movement)
test$lead_movement <- as.factor(test$lead_movement)

tree.gme.train=tree(lead_movement~., data=train)
tree.pred=predict(tree.gme.train,test,type="class")
tree.pred <- as.numeric(tree.pred) - 1
table(tree.pred, test$lead_movement)

accuracy <- (3+5)/(3+5+2+2)
error <- 1-accuracy

accuracy
error
```

The accuracy is thus 73%; whereas the error is 27%.

Now we turn to pruning the tree:

```{R}

cv.gme.tree <- cv.tree(tree.gme.train,FUN=prune.misclass) # FUN: classification error rate guides the cross-validation and pruning process; default: deviance 

par(mfrow=c(1,2))
plot(cv.gme.tree$size,cv.gme.tree$dev,type="b")
plot(cv.gme.tree$k,cv.gme.tree$dev,type="b")

```
We see that the optimal size is 1 or 2 as the number of terminal nodes.
Furthermore, the standard deviation is smallest with a cost-complexity parameter (alpha) of 1 to 3.
Based on model parsimony, we could pick 1 as the model size (least complex model). However, our model is already very simple, so it does not make sense to prune the tree.

The above is mostly meant as data exploration. If we want to predict, we should turn to bagging and boosting. (HOWEVER: Does this actually make sense for us? We dont really have a large amount of neither observations nor regressors)

```{R}



```

